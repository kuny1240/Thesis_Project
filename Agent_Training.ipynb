{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Agent_Training.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"AViIHeuChGkR","colab_type":"code","outputId":"77298e7b-6097-4fab-ad63-b011a335c608","executionInfo":{"status":"ok","timestamp":1557345488859,"user_tz":300,"elapsed":71104,"user":{"displayName":"杨坤","photoUrl":"","userId":"03321226440026420069"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import os\n","import time\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7Y2h0Kx9c4en","colab_type":"code","outputId":"69bb1dfc-a09e-4376-e4c7-e3ef27f5bc5f","executionInfo":{"status":"error","timestamp":1556809315570,"user_tz":300,"elapsed":10481,"user":{"displayName":"杨坤","photoUrl":"","userId":"03321226440026420069"}},"colab":{"base_uri":"https://localhost:8080/","height":769}},"source":["model =  tf.keras.models.load_model('/content/gdrive/My Drive/Colab Notebooks/Simulator/kpi_model_v2.h5')\n","# model.predict()\n","state = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Simulator/simulator_data_big1.csv',\n","                    index_col = None)[pos:pos+1].values\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-35017f4ac838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model.predict()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m state = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Simulator/simulator_data_big1.csv',\n\u001b[0;32m----> 4\u001b[0;31m                     index_col = None)[pos:pos+1].values\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nrows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m     \"\"\"\n\u001b[1;32m    574\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"woEDWfEPqjOV","colab_type":"code","outputId":"d3deca3e-59e6-4f04-976d-b73cfd2a8667","executionInfo":{"status":"ok","timestamp":1556087912580,"user_tz":300,"elapsed":402,"user":{"displayName":"杨坤","photoUrl":"","userId":"03321226440026420069"}},"colab":{"base_uri":"https://localhost:8080/","height":117}},"source":["rand = list(range(1,16)) + list(range(27,37))\n","k = np.random.binomial(1,.5,len(rand))\n","k[k==0] = -1\n","np.random.rand(len(rand)) * k"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.50256019, -0.26214076, -0.71131729,  0.52176441, -0.8584163 ,\n","       -0.27532678,  0.3613293 , -0.92735347, -0.01833002, -0.89159483,\n","       -0.8070151 , -0.81634683,  0.6039063 , -0.86674248,  0.79018918,\n","        0.94796045, -0.28477818,  0.79147042,  0.22354663,  0.20009982,\n","       -0.88067096,  0.91496748, -0.11099296, -0.0828404 , -0.53750756])"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"id":"4RrZgFT8Xu7K","colab_type":"code","colab":{}},"source":["class Simulator(object):\n","  def __init__(self):\n","    self.model =  tf.keras.models.load_model('/content/gdrive/My Drive/Colab Notebooks/Simulator/kpi_model_v2.h5')\n","    self.pos = 0\n","    self.state = np.array(35 * [0])\n","    self.act = 18 # this is the action column\n","    self.kpi = 3\n","    self.stationary = [17,19,20,21,22,23,24,25,26] # these cols won't change during the procedure\n","    self.rand = list(range(1,16)) + list(range(27,37))# these cols change a random gaussian noise with mean as the beginning status\n","    self.rand.remove(3)\n","    self.noise_base =  np.array([0] * 24)\n","    self.action_space =  np.array([40,50,60,70,80,90,100,110,120,130,140])\n","    self.cur_kpi = 0\n","  \n","  def reset(self):\n","    self.pos = int(np.round(np.random.rand(1)[0] * 1883614))\n","    self.state = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Simulator/simulator_data_big1.csv',\n","                    index_col = None)[self.pos:self.pos+1].values\n","    # basic possible states from existing points\n","    self.noise_base = self.state[:,self.rand] * 0.05 # at most 5% change\n","    self.cur_kpi = self.state[:,self.kpi]\n","    return self.state[:,list(range(1,3)) + list(range(4,37))]\n","  \n","  def step(self,action):\n","    self.state[:,self.act] = self.action_space[action]\n","    k = np.random.binomial(1,.5,len(self.rand))\n","    k[k==0] = -1\n","    self.state[:,self.rand] = self.noise_base * np.random.rand(len(self.rand)) * k + self.state[:,self.rand]\n","    pred_kpi = self.model.predict(self.state[:,list(range(1,3)) + list(range(4,37))])\n","    if self.cur_kpi != 0:\n","      r = (pred_kpi - self.cur_kpi)/self.cur_kpi\n","    else:\n","      r = 0.01\n","    if r >= 0.05:\n","      reward = 100\n","    elif r < -0.05:\n","      reward = -100\n","    else:\n","      reward = 1\n","    self.cur_kpi = pred_kpi\n","    \n","    return self.state[:,list(range(1,3)) + list(range(4,37))],reward\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WRWVpXD7otnA","colab_type":"code","outputId":"0598001a-edc5-48e9-e4e9-b975d31fb80e","executionInfo":{"status":"error","timestamp":1556948720354,"user_tz":300,"elapsed":4905802,"user":{"displayName":"杨坤","photoUrl":"","userId":"03321226440026420069"}},"colab":{"base_uri":"https://localhost:8080/","height":326}},"source":["\"\"\"\n","Simple policy gradient in Keras\n","\"\"\"\n","import numpy as np\n","import pandas as pd\n","\n","from keras import layers\n","from keras.models import Model\n","from keras import backend as K\n","from keras import utils as np_utils\n","from keras import optimizers\n","\n","\n","class Agent(object):\n","\n","    def __init__(self, input_dim, output_dim, hidden_dims=[32, 32]):\n","        \"\"\"The agent for single parameter tuning\n","        Args:\n","            input_dim (int): the dimension of state.\n","                Same as `env.observation_space.shape[0]`\n","            output_dim (int): the number of discrete actions\n","                Same as `env.action_space.n`\n","            hidden_dims (list): hidden dimensions\n","        Methods:\n","            private:\n","                __build_train_fn -> None\n","                    It creates a train function\n","                    It's similar to defining `train_op` in Tensorflow\n","                __build_network -> None\n","                    It create a base model\n","                    Its output is each action probability\n","            public:\n","                get_action(state) -> action\n","                fit(state, action, reward) -> None\n","        \"\"\"\n","\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","\n","        self.__build_network(input_dim, output_dim, hidden_dims)\n","        self.__build_train_fn()\n","\n","    def __build_network(self, input_dim, output_dim, hidden_dims=[32, 32]):\n","        \"\"\"Create a base network\"\"\"\n","        self.X = layers.Input(shape=(input_dim,))\n","        net = self.X\n","\n","        for h_dim in hidden_dims:\n","            net = layers.BatchNormalization()(net)\n","            net = layers.Dense(h_dim)(net)\n","            net = layers.Activation(\"relu\")(net)\n","\n","        net = layers.Dense(output_dim)(net)\n","        net = layers.Activation(\"softmax\")(net)\n","\n","        self.model = Model(inputs=self.X, outputs=net)\n","            \n","         \n","        #I set output to be 5 at first,(+5,+1,0,-1,-5)\n","\n","    def __build_train_fn(self):\n","        \"\"\"Create a train function\n","        It replaces `model.fit(X, y)` because we use the output of model and use it for training.\n","        For example, we need action placeholder\n","        called `action_one_hot` that stores, which action we took at state `s`.\n","        Hence, we can update the same action.\n","        This function will create\n","        `self.train_fn([state, action_one_hot, discount_reward])`\n","        which would train the model.\n","        \"\"\"\n","        action_prob_placeholder = self.model.output\n","        action_onehot_placeholder = K.placeholder(shape=(None, self.output_dim),\n","                                                  name=\"action_onehot\")\n","        discount_reward_placeholder = K.placeholder(shape=(None,),\n","                                                    name=\"discount_reward\")\n","\n","        action_prob = K.sum(action_prob_placeholder * action_onehot_placeholder, axis=1)\n","        log_action_prob = K.log(action_prob)\n","\n","        loss = - log_action_prob * discount_reward_placeholder\n","        loss = K.mean(loss)\n","\n","        adam = optimizers.Adam()\n","\n","        updates = adam.get_updates(params=self.model.trainable_weights,\n","                                   loss=loss)\n","\n","        self.train_fn = K.function(inputs=[self.model.input,\n","                                           action_onehot_placeholder,\n","                                           discount_reward_placeholder],\n","                                   outputs=[],\n","                                   updates=updates)\n","        \n","        \n","    def save(self,path):\n","      self.model.save(path)\n","      \n","    def read_model(self,path):\n","      self.model = tf.keras.models.load_model(path)\n","\n","    def get_action(self, state):\n","        \"\"\"Returns an action at given `state`\n","        Args:\n","            state (1-D or 2-D Array): It can be either 1-D array of shape (state_dimension, )\n","                or 2-D array shape of (n_samples, state_dimension)\n","        Returns:\n","            action: an integer action value ranging from 0 to (n_actions - 1)\n","        \"\"\"\n","        shape = state.shape\n","        action_prob = np.squeeze(self.model.predict(state))\n","        return np.random.choice(np.arange(self.output_dim), p=action_prob)\n","\n","    def fit(self, S, A, R):\n","        \"\"\"Train a network\n","        Args:\n","            S (2-D Array): `state` array of shape (n_samples, state_dimension)\n","            A (1-D Array): `action` array of shape (n_samples,)\n","                It's simply a list of int that stores which actions the agent chose\n","            R (1-D Array): `reward` array of shape (n_samples,)\n","                A reward is given after each action.\n","        \"\"\"\n","        action_onehot = np_utils.to_categorical(A, num_classes=self.output_dim)\n","        discount_reward = compute_discounted_R(R)\n","        S = S.reshape((-1,35))\n","        discount_reward = discount_reward.reshape(21)\n","        assert S.shape[1] == self.input_dim, \"{} != {}\".format(S.shape[1], self.input_dim)\n","        assert action_onehot.shape[0] == S.shape[0], \"{} != {}\".format(action_onehot.shape[0], S.shape[0])\n","        assert action_onehot.shape[1] == self.output_dim, \"{} != {}\".format(action_onehot.shape[1], self.output_dim)\n","        assert len(discount_reward.shape) == 1, \"{} != 1\".format(len(discount_reward.shape))\n","\n","        self.train_fn([S, action_onehot, discount_reward])\n","\n","\n","def compute_discounted_R(R, discount_rate=.99):\n","    \"\"\"Returns discounted rewards\n","    Args:\n","        R (1-D array): a list of `reward` at each time step\n","        discount_rate (float): Will discount the future value by this rate\n","    Returns:\n","        discounted_r (1-D array): same shape as input `R`\n","            but the values are discounted\n","    Examples:\n","        >>> R = [1, 1, 1]\n","        >>> compute_discounted_R(R, .99) # before normalization\n","        [1 + 0.99 + 0.99**2, 1 + 0.99, 1]\n","    \"\"\"\n","    discounted_r = np.zeros_like(R, dtype=np.float32)\n","    running_add = 0\n","    for t in reversed(range(len(R))):\n","\n","        running_add = running_add * discount_rate + R[t]\n","        discounted_r[t] = running_add\n","\n","#     discounted_r -= discounted_r.mean() / discounted_r.std()\n","\n","    return discounted_r\n","\n","\n","def run_episode(env, agent):\n","    \"\"\"Returns an episode reward\n","    (1) Play until the game is done\n","    (2) The agent will choose an action according to the policy\n","    (3) When it's done, it will train from the game play\n","    Args:\n","        env (gym.env): Gym environment\n","        agent (Agent): Game Playing Agent\n","    Returns:\n","        total_reward (int): total reward earned during the whole episode\n","    \"\"\"\n","#     done = False\n","    S = []\n","    A = []\n","    R = []\n","\n","    s = env.reset()\n","\n","    total_reward = 0\n","\n","    for i in range(21):\n","      a = agent.get_action(s)\n","      S.append(s)\n","      A.append(a)\n","      s2, r = env.step(a)\n","      total_reward += r\n","        \n","      R.append(r)\n","\n","      s = s2\n","\n","    S = np.array(S)\n","    A = np.array(A)\n","\n","    agent.fit(S, A, R)\n","\n","    return total_reward\n","\n","\n","\n","output_dim = 11\n","input_dim = 35\n","agent = Agent(input_dim, output_dim)\n","agent.read_model('/content/gdrive/My Drive/Colab Notebooks/Simulator/agent_v2.h5')\n","m = []\n","env = Simulator()\n","for j in range(200):\n","    r = 0\n","    for i in range(32):\n","      reward = run_episode(env, agent)\n","      r += reward\n","    agent.save('/content/gdrive/My Drive/Colab Notebooks/Simulator/agent_v2.h5')\n","    m.append(r/32)\n","    print(j,m[j])\n","    \n","df = pd.DataFrame(m)\n","df.to_csv('/content/gdrive/My Drive/Colab Notebooks/Simulator/epoch_reward.csv')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","0 41.53125\n","1 57.5\n","2 48.28125\n","3 78.84375\n","4 41.71875\n","5 57.3125\n","6 51.4375\n","7 23.34375\n","8 19.6875\n","9 13.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k3gspXNRNve2","colab_type":"code","outputId":"7db2eb2e-5e4b-4b42-aa98-3f4d8defd089","executionInfo":{"status":"error","timestamp":1557026492025,"user_tz":300,"elapsed":257,"user":{"displayName":"杨坤","photoUrl":"","userId":"03321226440026420069"}},"colab":{"base_uri":"https://localhost:8080/","height":230}},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(m)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-c0fc933dc0b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"]}]}]}